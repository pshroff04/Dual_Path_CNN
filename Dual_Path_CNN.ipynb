{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x21b7f798f90>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torchvision.models import resnet50\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "import json\n",
    "import re\n",
    "import string\n",
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "import gensim\n",
    "import pandas\n",
    "import cv2\n",
    "\n",
    "torch.random.manual_seed(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "isgpu = torch.cuda.is_available()\n",
    "print(isgpu)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#is gpu available\n",
    "isgpu = torch.cuda.is_available()\n",
    "#Dataset and preprocessing\n",
    "path = '../../../Downloads/GoogleNews-vectors-negative300.bin'           \n",
    "word2Vec = gensim.models.KeyedVectors.load_word2vec_format(path, binary=True)\n",
    "\n",
    "train_dataset = json.load(open('../Dataset/MSCOCO/annotations_trainval2014/annotations/captions_train2014.json', 'r'))\n",
    "test_dataset = json.load(open('../Dataset/MSCOCO/annotations_trainval2014/annotations/captions_val2014.json', 'r'))\n",
    "\n",
    "def preprocess(x):\n",
    "    #lower\n",
    "    x = x.lower()\n",
    "    #x = re.sub(r'\\d+','', x) #remove numbers\n",
    "    x = x.translate(str.maketrans('', '', string.punctuation))#remove punctuation\n",
    "    x = x.strip() #whitespace\n",
    "    return word_tokenize(x)\n",
    "#idx zero - reverse for zero padding\n",
    "idx=1\n",
    "vocab = set()\n",
    "word2idx= {}\n",
    "for dataset in (train_dataset, test_dataset):\n",
    "    for entry in dataset['annotations']:\n",
    "        text = entry['caption']\n",
    "        for word in preprocess(text):\n",
    "            if  word not in word2idx and word in word2Vec:\n",
    "                word2idx[word] = idx\n",
    "                vocab.add(word)\n",
    "                idx +=1\n",
    "                #print(min(list(word2idx.values())))\n",
    "\n",
    "weight_matrix = torch.zeros((len(vocab)+1, 300)) # weight matrix's first entry will be for zero index\n",
    "for word in word2idx.keys():\n",
    "    weight_matrix[word2idx[word]] = torch.from_numpy(word2Vec[word])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "zeroIndex = word2idx['0']\n",
    "word2Vec['0'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Image Data preprocessing\n",
    "\n",
    "class CustomDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, imgSize, transforms=None):\n",
    "        super(CustomDataLoader, self).__init__()\n",
    "        self.imgSize = imgSize\n",
    "        image = pd.DataFrame.from_dict(train_dataset['images'])\n",
    "        ann = pd.DataFrame.from_dict(train_dataset['annotations'])\n",
    "        \n",
    "        self.data = pd.merge(left=image, right=ann, left_on='id', right_on='image_id')\n",
    "        self.data.drop(columns=['coco_url', 'date_captured',  'flickr_url', 'height',\n",
    "           'id_x', 'license', 'width', 'id_y'], inplace=True)\n",
    "        self.data.drop_duplicates('image_id', inplace=True)\n",
    "        self.data.index = range(len(data))\n",
    "        \n",
    "    def __getitem__(self, index):\n",
    "        \n",
    "        #Get Image\n",
    "        path = '../Dataset/MSCOCO/image/train2014/'+ self.data.loc[index]['file_name']\n",
    "        img = cv2.imread(path)\n",
    "        img_w, img_h = img.shape[1], img.shape[0]\n",
    "        w, h = 256,256\n",
    "        new_w = round(img_w * min(w/img_w, h/img_h))\n",
    "        new_h = round(img_h * min(w/img_w, h/img_h))\n",
    "        resized_image = cv2.resize(img, (new_w,new_h), interpolation = cv2.INTER_CUBIC)\n",
    "        img = cv2.resize(img, self.imgSize)\n",
    "        img = img[:,:,::-1].transpose((2,0,1)).copy()        \n",
    "        img = torch.from_numpy(img).float().div(255.0)\n",
    "        \n",
    "        #Get textIndexs for embedding layer\n",
    "        caption = self.data.loc[index]['caption']\n",
    "        words = preprocess(caption)[:32]\n",
    "        index = [0 for _ in range(32)] #32- paper \n",
    "        for w in range(len(words)):\n",
    "            index[w]  = word2idx[words[w]]\n",
    "        wordIndex = torch.LongTensor(words)\n",
    "        #label = index\n",
    "        \n",
    "        \n",
    "        return img, wordIndex, index\n",
    "    \n",
    "    def __len__(self):\n",
    "        return self.data.shape[0]\n",
    "        \n",
    "ds = CustomDataset((224,224))\n",
    "loader = DataLoader(ds, shuffle=True, batch_size=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Model\n",
    "class ImageCNN(nn.Module):\n",
    "    \n",
    "    def __init__(self, stageI=True):\n",
    "        super(ImageCNN, self).__init__()\n",
    "        re = resnet50(pretrained=True)\n",
    "        #remove the last classification layer\n",
    "        self.resnet = nn.Sequential(*list(re.children())[:-1])\n",
    "        \n",
    "        #During StageI training -> resnet weights are fixed with pretrained weights\n",
    "        if stageI: \n",
    "            for weights in self.resnet.parameters():\n",
    "                weights.requires_grad_(False)\n",
    "        \n",
    "        self.fc = nn.Linear(2048, 2048)\n",
    "        self.bn = nn.BatchNorm1d(2048)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.dropOut = nn.Dropout(0.8)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.resnet(x) # (N,2048,1,1)\n",
    "        x = torch.flatten(x,1) # (N,2048)\n",
    "        x = self.relu(self.bn(self.fc(x)))\n",
    "        x = self.relu(self.bn(self.fc(x))) # As per their MATLAB implementation\n",
    "        return self.dropOut(x)\n",
    "\n",
    "##Test Model -> Input (N,3,224,224) and Output (N,2048)\n",
    "# net1 = ImageCNN()\n",
    "# x1= torch.rand((2,3,224,224))\n",
    "# y1 = net1(x1)\n",
    "# print(y1.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#textCNN -> The input should be the output of word2vec (N,300,32,1)\n",
    "class BasicBlockText(nn.Module):\n",
    "    \n",
    "    def __init__(self, input_channel, intermediate_channel):\n",
    "        super(BasicBlockText, self).__init__()\n",
    "        self.bbConv1 = nn.Conv2d(input_channel, intermediate_channel, \n",
    "                                 kernel_size=(1,1), stride=(1,1), \n",
    "                                 padding=(0,0), bias=False)\n",
    "        self.bbBatchNorm1 = nn.BatchNorm2d(intermediate_channel)\n",
    "        self.relu = nn.ReLU()\n",
    "        \n",
    "        self.bbConv2 = nn.Conv2d(intermediate_channel, intermediate_channel, \n",
    "                                 kernel_size=(1,2), stride=(1,1), \n",
    "                                 padding=(0,1),bias=False, dilation = (1,2))\n",
    "        self.bbBatchNorm2 = nn.BatchNorm2d(intermediate_channel)\n",
    "        \n",
    "        self.bbConv3 = nn.Conv2d(intermediate_channel, input_channel, kernel_size=(1,1), stride=(1,1), padding=(0,0), bias=False)\n",
    "        self.bbBatchNorm3 = nn.BatchNorm2d(input_channel)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        identity  = x\n",
    "        out = self.relu(self.bbBatchNorm1(self.bbConv1(x)))\n",
    "        out = self.relu(self.bbBatchNorm2(self.bbConv2(out)))\n",
    "        out = self.bbBatchNorm3(self.bbConv3(out))\n",
    "        \n",
    "        out += identity\n",
    "        return self.relu(out)\n",
    "\n",
    "\n",
    "        \n",
    "class textCNN(nn.Module):\n",
    "    \n",
    "    def __init__(self, input_channel, path): #300\n",
    "        super(textCNN, self).__init__()\n",
    "        self.relu = nn.ReLU()\n",
    "        #self.word2Vec = nn.Embedding.from_pretrained(self.__load_word2vec(path))\n",
    "        \n",
    "        self.emb_layer,_,_ = create_emb_layer(weight_matrix)\n",
    "        #--------First CNN block----------------\n",
    "        self.b1Conv1_0 = nn.Conv2d(input_channel, 128, \n",
    "                                 kernel_size=(1,1), stride=(1,1), \n",
    "                                 padding=(0,0), bias=False)\n",
    "        self.b1bn1_0 = nn.BatchNorm2d(128)\n",
    "        \n",
    "        self.b1Conv2 = nn.Conv2d(128, 128, \n",
    "                                 kernel_size=(1,2), stride=(1,1), \n",
    "                                 padding=(0,1), bias=False, dilation=(1,2))\n",
    "        self.b1bn2 = nn.BatchNorm2d(128)\n",
    "        \n",
    "        self.b1Conv3 = nn.Conv2d(128, 256, \n",
    "                                 kernel_size=(1,1), stride=(1,1), \n",
    "                                 padding=(0,0), bias=False)\n",
    "        self.b1bn3 = nn.BatchNorm2d(256)\n",
    "        \n",
    "        #input here too\n",
    "        self.b1Conv1_1 = nn.Conv2d(input_channel, 256,\n",
    "                               kernel_size=(1,1), stride=(1,1), \n",
    "                               padding=(0,0), bias=False)\n",
    "        self.b1bn1_1 = nn.BatchNorm2d(256)\n",
    "        \n",
    "        #Adding first basicblock (in matlab code i=2:3)\n",
    "        self.layer1  = self.__make_layer(input_channel=256, intermediate_channel=64, \n",
    "                                     num_blocks=2)\n",
    "        \n",
    "        #--------Second CNN block----------------\n",
    "        self.b2Conv1_0 = nn.Conv2d(256, 512, \n",
    "                                 kernel_size=(1,1), stride=(1,1), \n",
    "                                 padding=(0,0), bias=False)\n",
    "        self.b2bn1_0 = nn.BatchNorm2d(512)\n",
    "        \n",
    "        self.b2Conv2 = nn.Conv2d(512, 512, \n",
    "                                 kernel_size=(1,2), stride=(2,2), \n",
    "                                 padding=(0,1), bias=False, dilation= (1,2))\n",
    "        self.b2bn2 = nn.BatchNorm2d(512)\n",
    "        \n",
    "        self.b2Conv3 = nn.Conv2d(512, 512, \n",
    "                                 kernel_size=(1,1), stride=(1,1), \n",
    "                                 padding=(0,0), bias=False)\n",
    "        self.b2bn3 = nn.BatchNorm2d(512)\n",
    "        \n",
    "        self.b2Conv1_1 = nn.Conv2d(256, 512, \n",
    "                                 kernel_size=(1,1), stride=(2,2), \n",
    "                                 padding=(0,0), bias=False)\n",
    "        self.b2bn1_1 = nn.BatchNorm2d(512)\n",
    "        \n",
    "        #Add second basicblock (in matlb i = 2:4)\n",
    "        self.layer2 =  self.__make_layer(input_channel=512, intermediate_channel=128, \n",
    "                                     num_blocks=3)\n",
    "        \n",
    "        #--------Third CNN block----------------\n",
    "        self.b3Conv1_0 = nn.Conv2d(512, 1024, \n",
    "                                 kernel_size=(1,1), stride=(1,1), \n",
    "                                 padding=(0,0), bias=False)\n",
    "        self.b3bn1_0 = nn.BatchNorm2d(1024)\n",
    "        \n",
    "        self.b3Conv2 = nn.Conv2d(1024, 1024, \n",
    "                                 kernel_size=(1,2), stride=(2,2), \n",
    "                                 padding=(0,1), bias=False, dilation= (1,2))\n",
    "        self.b3bn2 = nn.BatchNorm2d(1024)\n",
    "        \n",
    "        self.b3Conv3 = nn.Conv2d(1024, 1024, \n",
    "                                 kernel_size=(1,1), stride=(1,1), \n",
    "                                 padding=(0,0), bias=False)\n",
    "        self.b3bn3 = nn.BatchNorm2d(1024)\n",
    "        \n",
    "        self.b3Conv1_1 = nn.Conv2d(512, 1024, \n",
    "                                 kernel_size=(1,1), stride=(2,2), \n",
    "                                 padding=(0,0), bias=False)\n",
    "        self.b3bn1_1 = nn.BatchNorm2d(1024)\n",
    "        \n",
    "        #Add third basicblock (in matlb i = 2:6)\n",
    "        self.layer3 =  self.__make_layer(input_channel=1024, intermediate_channel=256, \n",
    "                                     num_blocks=5)\n",
    "        \n",
    "        #------------------\n",
    "        self.b4Conv1_0 = nn.Conv2d(1024, 2048, \n",
    "                                 kernel_size=(1,1), stride=(1,1), \n",
    "                                 padding=(0,0), bias=False)\n",
    "        self.b4bn1_0 = nn.BatchNorm2d(2048)\n",
    "        \n",
    "        self.b4Conv2 = nn.Conv2d(2048, 2048, \n",
    "                                 kernel_size=(1,2), stride=(1,1), \n",
    "                                 padding=(0,1), bias=False, dilation= (1,2))\n",
    "        self.b4bn2 = nn.BatchNorm2d(2048)\n",
    "        \n",
    "        self.b4Conv3 = nn.Conv2d(2048, 2048, \n",
    "                                 kernel_size=(1,1), stride=(1,1), \n",
    "                                 padding=(0,0), bias=False)\n",
    "        self.b4bn3 = nn.BatchNorm2d(2048)\n",
    "        \n",
    "        self.b4Conv1_1 = nn.Conv2d(1024, 2048, \n",
    "                                 kernel_size=(1,1), stride=(1,1), \n",
    "                                 padding=(0,0), bias=False)\n",
    "        self.b4bn1_1 = nn.BatchNorm2d(2048)\n",
    "        \n",
    "        #------\n",
    "        self.avgpool = nn.AdaptiveAvgPool2d((1,1))\n",
    "        self.fc1 = nn.Linear(2048,2048)\n",
    "        self.fc1_bn = nn.BatchNorm1d(2048)\n",
    "        self.dropout = nn.Dropout(0.8)\n",
    "        \n",
    "    def __load_word2vec(self, path):\n",
    "        model = gensim.models.KeyedVectors.load_word2vec_format(path, binary=True)\n",
    "    \n",
    "    def create_emb_layer(weights_matrix, non_trainable=False):\n",
    "        num_embeddings, embedding_dim = weights_matrix.shape\n",
    "        emb_layer = torch.nn.Embedding(num_embeddings, embedding_dim)\n",
    "        emb_layer.load_state_dict({'weight': weights_matrix})\n",
    "        if non_trainable:\n",
    "            emb_layer.weight.requires_grad = False\n",
    "\n",
    "        return emb_layer, num_embeddings, embedding_dim\n",
    "\n",
    "       \n",
    "    def __make_layer(self, input_channel, intermediate_channel, num_blocks):\n",
    "        layers = []\n",
    "        for i in range(num_blocks):\n",
    "            layers.append(BasicBlockText(input_channel, intermediate_channel))\n",
    "        return nn.Sequential(*layers)  \n",
    "\n",
    "    def forward(self, x): #input x: (N, 300, 1, 32)\n",
    "        x = self.embed_layer(x)\n",
    "        #--------------------\n",
    "        identity = x\n",
    "        out = self.relu(self.b1bn1_0(self.b1Conv1_0(x)))\n",
    "        out = self.relu(self.b1bn2(self.b1Conv2(out)))\n",
    "        out = self.b1bn3(self.b1Conv3(out))\n",
    "        #print(out.shape)\n",
    "        out2 = self.b1bn1_1(self.b1Conv1_1(identity))\n",
    "        #print(out2.shape)\n",
    "        out2 +=out\n",
    "        out2 = self.relu(out2) # (N, 256, 1,32)\n",
    "        #Add 2 basicblock\n",
    "        out2 = self.layer1(out2) # (N,256,1,32)\n",
    "        #------------------\n",
    "        identity = out2\n",
    "        out3 = self.relu(self.b2bn1_0(self.b2Conv1_0(out2)))\n",
    "        out3 = self.relu(self.b2bn2(self.b2Conv2(out3)))\n",
    "        out3 = self.b2bn3(self.b2Conv3(out3))\n",
    "        \n",
    "        out4 = self.b2bn1_1(self.b2Conv1_1(identity))\n",
    "        out4 += out3\n",
    "        out4 = self.relu(out4)\n",
    "        #Add 3 basicblocks\n",
    "        out4 = self.layer2(out4)## (N,512,1,16)\n",
    "        #-------------------------------\n",
    "        identity = out4\n",
    "        out5 = self.relu(self.b3bn1_0(self.b3Conv1_0(out4)))\n",
    "        out5 = self.relu(self.b3bn2(self.b3Conv2(out5)))\n",
    "        out5 = self.b3bn3(self.b3Conv3(out5))\n",
    "        \n",
    "        out6 = self.b3bn1_1(self.b3Conv1_1(identity))\n",
    "        out6 += out5\n",
    "        out6 = self.relu(out6)\n",
    "        #Add 5 basicblocks\n",
    "        out6 = self.layer3(out6)## (N,1024,1,8)\n",
    "        #---------------------------------------\n",
    "        identity = out6\n",
    "        out7 = self.relu(self.b4bn1_0(self.b4Conv1_0(out6)))\n",
    "        out7 = self.relu(self.b4bn2(self.b4Conv2(out7)))\n",
    "        out7 = self.b4bn3(self.b4Conv3(out7))\n",
    "        \n",
    "        out8 = self.b4bn1_1(self.b4Conv1_1(identity))\n",
    "        out8 += out7\n",
    "        out8 = self.relu(out8)\n",
    "        #-------------\n",
    "        out8 = self.avgpool(out8)\n",
    "        out8 = torch.flatten(out8,1)\n",
    "        out8 = self.dropout(self.relu(self.fc1_bn(self.fc1(out8))))\n",
    "        return out8\n",
    "        \n",
    "##Test TextCNN\n",
    "# net2 = textCNN(300, '../../../Downloads/GoogleNews-vectors-negative300.bin')\n",
    "# x2 = torch.rand(2,300,1,32)\n",
    "# y2 = net2(x2)\n",
    "# print(y2.shape) # (N,2048)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#implement weight sharing class\n",
    "class Model(nn.Module):\n",
    "    def __init__(self, output, stageI=True):\n",
    "        super(Model, self).__init__()\n",
    "        self.weights = torch.rand((output, 2048)) #out_features, in_features\n",
    "        self.imageCNN = ImageCNN(stageI)\n",
    "        self.textCNN =  textCNN(300)\n",
    "        \n",
    "    def forward(self, img, txt):\n",
    "        img_out = self.imageCNN(img) # (N,2048)\n",
    "        txt_out = self.textCNN(txt) # (N,2048)\n",
    "        return F.linear(img_out, self.weights), F.linear(txt_out, self.weights)\n",
    "\n",
    "##Test whole model\n",
    "# net = Model()\n",
    "# img = torch.rand((2,3,224,224))\n",
    "# txt = torch.rand((2,300,1,32))\n",
    "# fc_img, fc_txt = net(img, txt)\n",
    "# print(fc_img.shape) #(N,113287)\n",
    "# print(fc_txt.shape) #(N,113287)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#define loss\n",
    "criteria = nn.CrossEntropyLoss()\n",
    "\n",
    "#define net\n",
    "net = Model(output=87)\n",
    "if isgpu:\n",
    "    net = net.cuda()\n",
    "#training\n",
    "epochs = 100\n",
    "for e in range(epochs):\n",
    "    for index, img, txt, label in enumerate(loader):\n",
    "        print(img.shape, txt.shape, label)\n",
    "        break"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
